# 发表论文

--------------
## 2024

<table>
  <tr>
    <th>会议</th>
    <!-- <th>时间</th> -->
    <th>论文</th>
    <th>摘要</th>
  </tr>
  <tr>
    <td><button>DAC 2024</button></td>
    <td>A Holistic Functionalization Approach to Optimizing Imperative Tensor Programs in Deep Learning</td>
    <td>A Holistic Functionalization Approach to Optimizing Imperative Tensor Programs in Deep Learning, 2023 年 11 月投稿，2024 年 6 月录用，其中，主要完成单位是：上海人工智能实验室，北京大学，上海交通大学，商汤，香港中文大学，第1作者麻津铭是项目参与人员。基于函数式编程中的不可变变量（Immutable Variable）和传统编译器中的静态单赋值技术（SSA），对带有控制流的命令式张量程序中的 View 语义进行优化。实验表明，工作对多个深度学习任务相比于主流的深度学习编译器有最高 1.8x 的优化。</td>
  </tr>
  <tr>
    <td><button>SC 2024</button></td>
    <td>Achieving Energetic Superiority Through System-Level Quantum Circuit Simulation</td>
    <td>Achieving Energetic Superiority Through System-Level Quantum Circuit Simulation，2024年4月投稿，2024年6月录用。针对生成不相关的随机量子电路样本挑战，利用大规模系统技术，研究了如何突破内存限制和提高计算效率，提出了一种在全局、节点和设备层面进行优化的创新方法，实验表明该方法能够处理高达数十太字节的大规模张量网络，在速度和能效方面均优于Google的Sycamore量子处理器，为课题开展高性能、高扩展的三维并行融合调度训练系统在系统设计、性能优化等多个方面提供了理论支撑。</td>
  </tr>
  <tr>
    <td><button>COLM 2024</button></td>
    <td>SKVQ: Sliding-window Key and Value Cache Quantization for Large Language Models</td>
    <td>本工作提出了 SKVQ（滑动窗口 KV 缓存量化）来量化LLM推理过程中产生的 KV Cache。SKVQ 通过利用注意力模块的性质大幅提高KV缓存量化精度。实验评估表明，SKVQ 优于以前的量化方法，可以将 KV 缓存量化为 2-bit Key和 1.5-bit Value，只带来很小精度损失。这一改进允许在 80GB GPU 上为 7B 参数模型处理高达 1M 个令牌的上下文长度，理论解码速度提高 7 倍。</td>
  </tr>
  <tr>
    <td><button>ECCV workshop 2024</button></td>
    <td>Fisheye-GS: Lightweight and Extensible Gaussian Splatting Module for Fisheye Cameras</td>
    <td>提出了鱼眼高斯，通过重新计算鱼眼相机的投影变换及其梯度，解决了3D高斯喷洒（3DGS）在不同相机模型，特别是鱼眼镜头上的适应性问题，显著提升了视觉质量，并展示了其模块化设计的轻量级和可扩展性。</td>
  </tr>
  <tr>
    <td><button>ECCV workshop</button></td>
    <td>PackMamba: Efficient Processing of Variable-Length Sequences in Mamba Training</td>
    <td>提出了 PackMamba，通过优化 Mamba 架构中的瓶颈算子，实现了对可变长度序列的高效处理，显著提升了 NVIDIA A100 GPU 上的吞吐量，分别在 1.4B 和 2.8B 模型上实现了 3.06 倍和 2.62 倍的加速。</td>
  </tr>
  <!-- 更多行和单元格 -->
</table>
